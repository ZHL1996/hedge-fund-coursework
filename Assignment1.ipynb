{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kknqZZRPtK0t"
   },
   "source": [
    "# Advanced Risk Management – Assignment 1\n",
    "\n",
    "**Deadline**:  February 21, 18:00.\n",
    "\n",
    "| |Name |Student number|Email|\n",
    "|:-|:----|:-------------|:----|\n",
    "|1.|  |        |     |\n",
    "|2.|  |        |     |\n",
    "|3.|  |        |     |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "****Hand in the following via Canvas****:\n",
    "* Your notebook.\n",
    "* A (printed) pdf version of your notebook. In Google Colab, this is most conveniently done in the Chrome browser, and then using the **`File` -> `Print`** menu option; you may have to print in landscape mode to make sure that everything appears in the pdf.\n",
    "\n",
    "****Notes****:\n",
    "* The assignment is part of the examination, so the usual rules regarding plagiarism and fraud apply.\n",
    "* Before submitting your work, click on **`Runtime`-> `Restart and run all ...`** and verify that your notebook produces the desired results and does not error.\n",
    "\n",
    "**Declaration of Originality**: We whose names are given under 1. and 2. above declare that these solutions are solely our own work, and that we have not made these solutions available to any other student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyVcGIhkzW1b"
   },
   "source": [
    "## Introduction\n",
    "The file `RV_data.xlsx` contains daily data (January 2000 – February 2020, or a sub-period), for a number of international stock market indices, on the open-to-close log-return R (measured as percentage) and the daily realized variance RV (obtained from 5-minute returns).\n",
    "A list of the included indices is given on the website of the data provider, see\n",
    "https://realized.oxford-man.ox.ac.uk/data/assets (in the Excel file, the leading '.' has been removed from the symbol; e.g. `FCHI` instead of `.FCHI`). In this assignment, you are asked to estimate, test and compare two GARCH models for one of the indices in terms of their in-sample fit and their out-of-sample forecast quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4v62A5fYBUgU"
   },
   "source": [
    "## Question 1: Load and display data\n",
    "First, install and import the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2b_YQlgBYt9"
   },
   "outputs": [],
   "source": [
    "# !pip install arch             # uncomment for installing the arch package\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from arch import arch_model\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1m5W_Ks1CNUX"
   },
   "source": [
    "Next, import the data and obtain the returns for one chosen index. Uncomment and adapt the lines necessary to mount the drive and change the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDThtdbZz_KU"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = '/content/drive/...'    # change path to your working directory\n",
    "# os.chdir(path)\n",
    "df = pd.read_excel('RV_data.xlsx')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
    "df = df.set_index(['Date'])\n",
    "sel = df['Symbol']=='ABC'   # Boolean array to select index;\n",
    "                            # change 'ABC' to chosen index symbol, e.g., 'FCHI'\n",
    "R = df['R'].loc[sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kityY-O2LB4h"
   },
   "source": [
    "Display a line graph of the returns, and display the autocorrelation function of the returns and of the squared returns. Discuss whether you find the \"stylized facts\" mentioned in the textbook and slides of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZvqwr1FLReZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60C90oALLThc"
   },
   "source": [
    "Discussion of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Thc8rvtK0y"
   },
   "source": [
    "## Question 2: Fitting a symmetric GARCH model\n",
    "Estimate and test a GARCH model for the returns, using only data over the sub-period January 2000 – December 2012. For this question, do **not** consider a GJR-GARCH model or any model with an asymmetric NIC (see next question), but focus on standard GARCH($p,q$) models. Display and discuss the estimation output, and test the model for the absence of volatility clustering in the standardized residuals (shocks) $\\hat{z}_t$. If you try out various GARCH models, only report discuss the results on the final model.\n",
    "\n",
    "Note: estimation over a sub-sample using the ARCH package can be done by specifying `last_obs =` in the `.fit` function; see https://arch.readthedocs.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFhK9P4kvOzh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLiGCe2TtK1E"
   },
   "source": [
    "Discussion of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkpnWjK_tK1M"
   },
   "source": [
    "## Question 3: Fitting an asymmetric GARCH model\n",
    "(a) Extend the model you obtained above with one or more asymmetric terms (leading to a GJR-GARCH model), and estimate this second model using data over the same sub-period. Analogously to Question 2, display and discuss the estimation output, and test for volatility clustering in $\\hat{z}_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TT_mZiVDtK1Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSjBCoWCtK1c"
   },
   "source": [
    "Discussion of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfyoWylOMMhq"
   },
   "source": [
    "(b) Carry out a likelihood ratio test for the symmetric model of Question 2 (the null hypothesis) against the asymmetric model of Question 3 (the alternative hypothesis). Obtain the p-value of the test from the `scipy.stats` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACcEa4ZeNGNy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2V40yIRHNQnk"
   },
   "source": [
    "Discussion of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6tQe0TbOf7i"
   },
   "source": [
    "## Question 4: Comparing the out-of-sample fit\n",
    "From the two models estimated above, obtain the out-of-sample (one-step-ahead) conditional variance predictions over the period January 2013 – February 2020. These are based on coefficient estimates from data until 2012, but they use the most recent returns $R_t$ to obtain the predictions for $\\sigma_{t+1}^2$ in the period after 2012 (consult the ARCH package documentation for details).\n",
    "\n",
    "(a) Make a new data-frame containing the two sets of variance predictions, as wel as the realized variance for the same index and over the same sub-period (January 2013 – February 2020). Make a plot of the two predicted volatility series (square root of the predicted variances) in one figure, and discuss similarities and differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5W8ahhprOfFo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHynI0j1R9Ua"
   },
   "source": [
    "Discussion of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ll_h2p6SAsT"
   },
   "source": [
    "(b) Calculate the mean squared error of the two variance predictions (using the realized variance as the true $\\sigma_{t+1}^2$), and discuss the result; which one of the two models gives the best predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AY0kgGeAT4YQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PQiY8IiT45I"
   },
   "source": [
    "Discussion of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9b613jGT62n"
   },
   "source": [
    "(c) As discussed in Sections 4.6.3 and 5.7 of the book, variance forecasts $\\hat{\\sigma}_{t+1}^2$ can be evaluated in the linear regression\n",
    "\n",
    "$RV_{t+1} = b_0 + b_1\\hat{\\sigma}_{t+1}^2 + e_{t+1}$,\n",
    "\n",
    "by testing the two restrictions $b_0=0, b_1=1$ (separately and jointly).\n",
    "Estimate this regression twice: first, using the symmetric GARCH model prediction (Question 2), and next, using the asymmetric GARCH model prediction (Question 3) as explanatory variable. Report the estimation results and the outcome of the $F$-test for $b_0=0, b_1=1$ (use heteroskedasticity-robust standard errors). What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFVpnAS7WgY9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cV359BPWdeY"
   },
   "source": [
    "Discussion of results:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
